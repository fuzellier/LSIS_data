{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from pyproj import Transformer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of paths for each XML file in each folder\n",
    "file_list = []\n",
    "\n",
    "de_months = ['Januar', 'Februar', 'März', 'April', 'Mai', 'Juni',\n",
    "            'Juli', 'August', 'September', 'Oktober', 'November', 'Dezember']\n",
    "\n",
    "en_months = ['January', 'February', 'March', 'April', 'May', 'June',\n",
    "            'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "for i in os.listdir('data/')[:-2]: # skipping fixed & raw folders\n",
    "    \n",
    "    for filename in os.listdir('data/' + str(i) + '/'):\n",
    "        \n",
    "        for de_m, en_m in zip(de_months, en_months):\n",
    "        \n",
    "            # Renaming original files (and moving if year in name != year in path)\n",
    "            if bool(re.search(de_m, filename)) == True:\n",
    "\n",
    "                # Get year string from file name \n",
    "                # (not from the path, to prevent issues if a file is a wrong dir)\n",
    "                year = re.split('(?:.*?\\ ){2}([^\\.?#]+)', filename)[1]\n",
    "                \n",
    "                # Creating folder (for another year) if it does not exist yet\n",
    "                if not os.path.exists('data/' + year):\n",
    "                    os.makedirs('data/' + year)\n",
    "                \n",
    "                os.rename(\n",
    "                    'data/' + i + '/' + filename, \n",
    "                    'data/' + year + '/' + str((en_months.index(en_m) + 1)) + '_' + year + \"_\" + en_m.lower() + '.xml'\n",
    "                )\n",
    "\n",
    "                filename = str((en_months.index(en_m) + 1)) + '_' + year + \"_\" + en_m.lower() + '.xml'\n",
    "        \n",
    "        # Filling list of paths for each XML file in each folder\n",
    "        if filename.endswith(\".xml\"): \n",
    "            \n",
    "            # Year string from new file name\n",
    "            year = re.split('^[^_]+_([^_]+)_[^_]+$', filename)[1]\n",
    "            \n",
    "            # Append path to the list\n",
    "            file_list.append(os.path.join('data/' + year + '/', filename))\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split(r'(\\d+)', text)]\n",
    "\n",
    "# Sorting the list, human order\n",
    "file_list.sort(key = natural_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MISSION DataFrame\n",
    "def mission_infos(root): # root: input XML file root node\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'mission_id'          : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/eid')],\n",
    "        'mission_nb'          : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/einsatz_nr')],\n",
    "        'mission_type'        : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/einsatztyp')],\n",
    "        'mission_tags'        : [x.text.strip() for x in root.findall('./Einsatz/Einsatzgrunddaten/schlagwort')],\n",
    "        'keyword_1'           : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/einsatzstichwort1')],\n",
    "        'keyword_2'           : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/einsatzstichwort2')],\n",
    "        'keyword_3'           : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/einsatzstichwort3')],\n",
    "        'keyword_4'           : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/einsatzstichwort4')],\n",
    "        'keyword_5'           : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/einsatzstichwort5')],\n",
    "        'keyword_6'           : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/einsatzstichwort6')],\n",
    "        \n",
    "        # Non-relevant data still present but filled with null values\n",
    "        'blue_light'          : [None for i in range(len(root))],\n",
    "        'free_text'           : [None for i in range(len(root))],\n",
    "        'invoicing_type'      : [None for i in range(len(root))],\n",
    "        'final_keyword'       : [None for i in range(len(root))],\n",
    "        'father_id'           : [None for i in range(len(root))],\n",
    "        'mft_id'              : [None for i in range(len(root))],\n",
    "        'standing_order_id'   : [None for i in range(len(root))],\n",
    "        'plan_date'           : [None for i in range(len(root))],\n",
    "        'fix'                 : [None for i in range(len(root))],\n",
    "        \n",
    "        'dispatch_center'     : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/leitstelle')],\n",
    "        \n",
    "        'transfer_status'     : [None for i in range(len(root))], \n",
    "        'kez_status'          : [None for i in range(len(root))],\n",
    "        \n",
    "        'call_time'           : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/meldeeingang')],\n",
    "        'call_accept_time'    : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/rufannahme')],\n",
    "        'input_db_time'       : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/beginn_meldungsaufnahme')],\n",
    "        'end_input_db_time'   : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/ende_meldungsaufnahme')],\n",
    "        'info_transfer_time'  : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/weiterleitung')],\n",
    "        'end_mission_time'    : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/einsatzende')],\n",
    "        'travel_time'         : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/fahrtdauer')],\n",
    "        'travel_dist_km'      : [x.text for x in root.findall('./Einsatz/Einsatzgrunddaten/fahrtkm')],\n",
    "    })\n",
    "    \n",
    "    # Formatting timestamp data\n",
    "    l = ['call_time', 'input_db_time', 'end_mission_time']\n",
    "\n",
    "    for i in l:\n",
    "        df[i][df[i].notnull()] = [\n",
    "            pd.to_datetime(x, format = '%d.%m.%Y %H:%M:%S') for x in df[i] if x is not None]\n",
    "    \n",
    "    l2 = ['call_accept_time', 'end_input_db_time', 'info_transfer_time']\n",
    "\n",
    "    for i in l2:\n",
    "        df[i][df[i].notnull()] = [\n",
    "            pd.to_datetime(x, format = '%d.%m.%Y-%H:%M:%S') for x in df[i] if x is not None]\n",
    "    \n",
    "    df.apply(lambda x: x.str.strip() if x.dtype == \"str\" else x)\n",
    "    \n",
    "    return df   \n",
    "# end function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCATION DataFrame\n",
    "def location_infos(root): # root: input XML file root node\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'object'                   : [x.text for x in root.findall('./Einsatz/Einsatzort/eo_objekt')],\n",
    "        'department'               : [x.text for x in root.findall('./Einsatz/Einsatzort/eo_objekt_abteilung')],\n",
    "        'street'                   : [x.text for x in root.findall('./Einsatz/Einsatzort/eo_strasse')],\n",
    "        'city'                     : [x.text for x in root.findall('./Einsatz/Einsatzort/eo_ort')],\n",
    "        'zip'                      : [x.text for x in root.findall('./Einsatz/Einsatzort/eo_plz')],\n",
    "        'x_coord'                  : [x.text for x in root.findall('./Einsatz/Einsatzort/eo_xkoord')],\n",
    "        'y_coord'                  : [x.text for x in root.findall('./Einsatz/Einsatzort/eo_ykoord')],\n",
    "        'city_district'            : [x.text for x in root.findall('./Einsatz/Einsatzort/eo_ortsteil')],\n",
    "        'county'                   : [x.text for x in root.findall('./Einsatz/Einsatzort/eo_kreis')],\n",
    "        'district'                 : [x.text for x in root.findall('./Einsatz/Einsatzort/eo_bezirk')],\n",
    "        'alias'                    : [x.text for x in root.findall('./Einsatz/Einsatzort/eo_aliasname')],\n",
    "        'type'                     : [x.text for x in root.findall('./Einsatz/Einsatzort/eo_objekttyp')],\n",
    "        'department_type_hospital' : [x.text for x in root.findall('./Einsatz/Einsatzort/eo_kh_abteilungtyp')]\n",
    "    })\n",
    "    \n",
    "    # Formatting city_district (slicing before blank + '(' or '-')\n",
    "    df['city_district'][df['city_district'].notnull()] = [\n",
    "        re.split(' [(-].*$', x)[0] for x in [x for x in df['city_district']] if x is not None]\n",
    "    \n",
    "    # Coordinates convertion from Gauss-Krüger format to lat/long (WGS84)\n",
    "    # 5678 = DHDN / 3-degree Gauss-Krüger zone 4  (CRS code 31468) but with axis order reversed for GIS applications\n",
    "    # 4326 = WGS84\n",
    "    transformer = Transformer.from_crs(\"epsg:5678\", \"epsg:4326\")\n",
    "    coord_x = []\n",
    "    coord_y = []\n",
    "\n",
    "    for i, j in zip(df['x_coord'], df['y_coord']):\n",
    "        if i and j is not None:\n",
    "            x, y  = transformer.transform(i, j)\n",
    "            coord_x.append(x)\n",
    "            coord_y.append(y)\n",
    "        else:\n",
    "            coord_x.append(i)\n",
    "            coord_y.append(j)\n",
    "\n",
    "    # Replace both columns by coord_x, coord_y lists and convert is as numeric\n",
    "    df['x_coord'], df['y_coord'] = pd.to_numeric(coord_x), pd.to_numeric(coord_y)\n",
    "    \n",
    "    df.apply(lambda x: x.str.strip() if x.dtype == \"str\" else x)\n",
    "    \n",
    "    return df\n",
    "# end function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESTINATION DataFrame\n",
    "def destination_infos(root): # root: input XML file root node\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'object'                   : [x.text for x in root.findall('./Einsatz/Zielort/zo_objekt')],\n",
    "        'department'               : [x.text for x in root.findall('./Einsatz/Zielort/zo_objekt_abteilung')],\n",
    "        'street'                   : [x.text for x in root.findall('./Einsatz/Zielort/zo_strasse')],\n",
    "        'city'                     : [x.text for x in root.findall('./Einsatz/Zielort/zo_ort')],\n",
    "        'zip'                      : [x.text for x in root.findall('./Einsatz/Zielort/zo_plz')],\n",
    "        'x_coord'                  : [x.text for x in root.findall('./Einsatz/Zielort/zo_xkoord')],\n",
    "        'y_coord'                  : [x.text for x in root.findall('./Einsatz/Zielort/zo_ykoord')],\n",
    "        'city_district'            : [x.text for x in root.findall('./Einsatz/Zielort/zo_ortsteil')],\n",
    "        'county'                   : [x.text for x in root.findall('./Einsatz/Zielort/zo_kreis')],\n",
    "        'district'                 : [x.text for x in root.findall('./Einsatz/Zielort/zo_bezirk')],\n",
    "        'alias'                    : [x.text for x in root.findall('./Einsatz/Zielort/zo_aliasname')],\n",
    "        'type'                     : [x.text for x in root.findall('./Einsatz/Zielort/zo_objekttyp')],\n",
    "        'department_type_hospital' : [x.text for x in root.findall('./Einsatz/Zielort/zo_kh_abteilungtyp')],\n",
    "        'hospital_specialty'       : [x.text for x in root.findall('./Einsatz/Zielort/zo_kh_fachrichtung')]\n",
    "    })\n",
    "    \n",
    "    # Formatting city_district (slicing before blank + '(' or '-')\n",
    "    df['city_district'][df['city_district'].notnull()] = [\n",
    "        re.split(' [(-].*$', x)[0] for x in [x for x in df['city_district']] if x is not None]\n",
    "    \n",
    "    # Coordinates convertion from Gauss-Krüger format to lat/long (WGS84)\n",
    "    # 5678 = DHDN / 3-degree Gauss-Krüger zone 4  (CRS code 31468) but with axis order reversed for GIS applications\n",
    "    # 4326 = WGS84\n",
    "    transformer = Transformer.from_crs(\"epsg:5678\", \"epsg:4326\")\n",
    "    coord_x = []\n",
    "    coord_y = []\n",
    "\n",
    "    for i, j in zip(df['x_coord'], df['y_coord']):\n",
    "        if i and j is not None:\n",
    "            x, y  = transformer.transform(i, j)\n",
    "            coord_x.append(x)\n",
    "            coord_y.append(y)\n",
    "        else:\n",
    "            coord_x.append(i)\n",
    "            coord_y.append(j)\n",
    "\n",
    "    # Replace both columns by coord_x, coord_y lists and convert is as numeric\n",
    "    df['x_coord'], df['y_coord'] = pd.to_numeric(coord_x), pd.to_numeric(coord_y)\n",
    "    \n",
    "    df.apply(lambda x: x.str.strip() if x.dtype == \"str\" else x)\n",
    "    \n",
    "    return df  \n",
    "# end function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSETS DataFrame\n",
    "def assets_infos(root): # root: input XML file root node\n",
    "    \n",
    "    df_sub  = pd.DataFrame({})\n",
    "    df_time = pd.DataFrame({})\n",
    "    \n",
    "    assets_col_sub = [\n",
    "        'did', 'asset_type', 'asset_type_2', 'id', 'radio_name', 'radio_id', \n",
    "        'station', 'station_id', 'driving_time', 'distance', 'job_nb', 'x_coord', \n",
    "        'y_coord', 'asset_public', 'invoice_nb', 'station_nb', 'station_name'\n",
    "    ]\n",
    "    \n",
    "    assets_time_col = [\n",
    "        'begin_mission_time', 'alert_time', 'responding_time', 'arrival_time', \n",
    "        'leaving_time', 'arrival_patient_time', 'back_vehicle_time', 'back_station_time', \n",
    "        'ready_mission_time', 'asset_time_penalty', 'requesting_radio_call', 'radio_call_acceptance'\n",
    "    ]\n",
    "    \n",
    "    # Asset columns names (german)\n",
    "    de_assets_col = [x.tag for x in root[0][3]]\n",
    "    \n",
    "    # Asset columns except timestamps (german)\n",
    "    de_assets_col_sub = list(filter(re.compile('^(?!em_zeit|sprechwunsch)').match, de_assets_col))\n",
    "    \n",
    "    # Timestamps columns names (german)\n",
    "    de_assets_time = list(filter(re.compile('^(em_zeit|sprechwunsch)').match, de_assets_col))\n",
    "    \n",
    "    # Assets DataFrame (w/o timestamps and non-relevant cols)\n",
    "    for i, j in zip(assets_col_sub, de_assets_col_sub):\n",
    "        assets_sub = []\n",
    "\n",
    "        for k in range(len(root.findall('./Einsatz'))):\n",
    "            assets_sub.append(\n",
    "                [x.text for x in root[k].findall('./Einsatzmittel/' + j)]\n",
    "            )\n",
    "\n",
    "        df_sub[i] = assets_sub\n",
    "\n",
    "        assets_sub = []\n",
    "    \n",
    "    # Given the inversion in the form itself, swap x_coord y_coord columns values\n",
    "    df_sub.loc[:, ['x_coord','y_coord']] = df_sub.loc[:, ['y_coord', 'x_coord']].values\n",
    "    \n",
    "    # Assets timestamps DataFrame (except 2 last)\n",
    "    for i, j in zip(assets_time_col[:-2], de_assets_time[:-2]):\n",
    "        assets_timestamp = []\n",
    "\n",
    "        for k in range(len(root.findall('./Einsatz'))):\n",
    "            assets_timestamp.append(\n",
    "                [\n",
    "                    pd.to_datetime(\n",
    "                        x.text, errors = 'coerce', format = '%d.%m.%Y %H:%M:%S'\n",
    "                    ) for x in root[k].findall('./Einsatzmittel/' + j)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        df_time[i] = assets_timestamp\n",
    "\n",
    "        assets_timestamp = []\n",
    "    \n",
    "    # Add 2 lasts timestamps elements (handling \"-\" in the regex format)\n",
    "    for i, j in zip(assets_time_col[-2:], de_assets_time[-2:]):\n",
    "        assets_timestamp_2 = []\n",
    "\n",
    "        for k in range(len(root.findall('./Einsatz'))):\n",
    "            assets_timestamp_2.append(\n",
    "                [\n",
    "                    pd.to_datetime(\n",
    "                        x.text, errors = 'coerce', format = '%d.%m.%Y-%H:%M:%S'\n",
    "                    ) for x in root[k].findall('./Einsatzmittel/' + j)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        df_time[i] = assets_timestamp_2\n",
    "\n",
    "        assets_timestamp_2 = []\n",
    "    \n",
    "    # Concatenation, output df\n",
    "    df = pd.concat([df_sub, df_time], axis = 1)\n",
    "    \n",
    "    df.apply(lambda x: x.str.strip() if x.dtype == \"str\" else x)\n",
    "        \n",
    "    return df\n",
    "# end function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dataframes into JSON objects\n",
    "def df_to_json(df_list): \n",
    "    \n",
    "    '''\n",
    "    Usage:\n",
    "            parsed_data = df_to_json(df_list)\n",
    "\n",
    "    Arguments:\n",
    "            df_list    - list of dataframes\n",
    "\n",
    "    Returns:\n",
    "            a list of JSON objects (parsed dataframes)\n",
    "    '''\n",
    "    \n",
    "    res_mission = df_list[0].to_json(\n",
    "        orient = \"records\", date_format = \"iso\", date_unit = \"s\")\n",
    "    parsed_mission = json.loads(res_mission)\n",
    "\n",
    "    res_location = df_list[1].to_json(\n",
    "        orient = \"records\", date_format = \"iso\", date_unit = \"s\")\n",
    "    parsed_location = json.loads(res_location)\n",
    "\n",
    "    res_destination = df_list[2].to_json(\n",
    "        orient = \"records\", date_format = \"iso\", date_unit = \"s\")\n",
    "    parsed_destination = json.loads(res_destination)\n",
    "\n",
    "    res_assets = df_list[3].to_json(\n",
    "        orient = \"records\", date_format = \"iso\", date_unit = \"s\")\n",
    "    parsed_assets = json.loads(res_assets)\n",
    "\n",
    "    return([parsed_mission, parsed_location, parsed_destination, parsed_assets])\n",
    "# end function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the final JSON object\n",
    "def json_obj(dict_size, parsed_data):\n",
    "    \n",
    "    '''\n",
    "    Usage:\n",
    "            json_data = json_obj(dict_size, parsed_data)\n",
    "\n",
    "    Arguments:\n",
    "            dict_size    - dictionary size (nb of records)\n",
    "            parsed_data  - list of JSON objects\n",
    "\n",
    "    Returns:\n",
    "            json_data    - final JSON object\n",
    "    '''\n",
    "\n",
    "    # Creating dict (json_data) skeleton\n",
    "    missions_data = [None] * dict_size\n",
    "\n",
    "    for i in range(dict_size):\n",
    "        missions_data[i] = { \"infos\": {}, \"location\": {}, \"destination\": {}, \"assets\": [] }\n",
    "        \n",
    "    # Filling the dict\n",
    "    col_assets = list(df_list[3])\n",
    "\n",
    "    for i in range(dict_size):\n",
    "        missions_data[i]['infos']       = parsed_data[0][i]\n",
    "        missions_data[i]['location']    = parsed_data[1][i]\n",
    "        missions_data[i]['destination'] = parsed_data[2][i]\n",
    "\n",
    "        # Filling assets lists\n",
    "        for j in range(len(parsed_data[3][i]['begin_mission_time'])):\n",
    "            assets_json = {}\n",
    "\n",
    "            for item in col_assets:\n",
    "                assets_json[item] = parsed_data[3][i][item][j]\n",
    "\n",
    "            missions_data[i]['assets'].append(assets_json) \n",
    "    \n",
    "    # Storing in a 'missions' object\n",
    "    json_data = {}\n",
    "    json_data['missions'] = missions_data\n",
    "    \n",
    "    return(json_data)\n",
    "# end function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the JSON output file\n",
    "def json_output(data, file, path, in_ext = '.xml', out_ext = '.json'):\n",
    "    \n",
    "    '''\n",
    "    Usage:\n",
    "            json_file = json_output(data, file, path, in_ext, out_ext)\n",
    "\n",
    "    Arguments:\n",
    "            data      - input data to write in the output file\n",
    "            file      - input file from which to extract the name \n",
    "            path      - new folder where to save the file\n",
    "            in_ext    - input file (2nd argument) extension  (default value: '.xml')\n",
    "            out_ext   - output file extension                (default value: '.json')\n",
    "\n",
    "    Returns:\n",
    "            json_file - output file (same name as the input file, with another extension)\n",
    "    '''\n",
    "\n",
    "    # Extract file name from path name (after 2nd slash \"/\")\n",
    "    fname = re.split('(?:.*?\\/){2}([^\\/?#]+)', file)[1]\n",
    "    fout  = fname.replace(in_ext, out_ext) # replace in_ext extension by out_ext\n",
    "    \n",
    "    # Create output folder if it does not exist yet\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    # JSON output file, now renamed with XML input name\n",
    "    with open(path + '/' + fout, 'w', encoding = 'utf-8') as json_file:\n",
    "        json.dump(data, json_file, ensure_ascii = False, indent = 4)\n",
    "        \n",
    "    return(json_file)\n",
    "# end function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Processing...]: 100%|█████████████████████████████| 41/41 [00:44<00:00,  1.10s/it, 5_2021_may.xml has been processed.]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the files have been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the list that contains file paths\n",
    "# Then open each one and execute the whole script for each\n",
    "\n",
    "# Progress bar\n",
    "pbar = tqdm(file_list)\n",
    "\n",
    "for f in pbar:\n",
    "    \n",
    "    # Getting the input XML file root node\n",
    "    with open(f, 'r', encoding = 'utf-8') as xml_file:\n",
    "        root = ET.parse(xml_file).getroot()\n",
    "    \n",
    "    # Progress bar message\n",
    "    pbar.set_description(\"[Processing...]\")\n",
    "       \n",
    "    # Get file name\n",
    "    fname = re.split('(?:.*?\\/){2}([^\\/?#]+)', f)[1]\n",
    "          \n",
    "    # Get year string from file name\n",
    "    year  = re.split('^[^_]+_([^_]+)_[^_]+$', f)[1]\n",
    "    \n",
    "    # If JSON version of 'f 'doesn't exist, run the whole process\n",
    "    if not os.path.isfile(os.path.join('output/', re.split('data/', f.replace('.xml', '.json'))[1])):\n",
    "\n",
    "        # Building dataframes\n",
    "        mission_df     = mission_infos(root)\n",
    "        location_df    = location_infos(root)\n",
    "        destination_df = destination_infos(root)\n",
    "        assets_df      = assets_infos(root)\n",
    "\n",
    "        # List of built dataframes\n",
    "        df_list = [mission_df, location_df, destination_df, assets_df]\n",
    "\n",
    "        # Calling fct to convert dataframes into JSON objects\n",
    "        parsed_data = df_to_json(df_list)\n",
    "\n",
    "        # Calling fct to build the final JSON object\n",
    "        json_data = json_obj(len(parsed_data[0]), parsed_data)\n",
    "        \n",
    "        # Generating the JSON file\n",
    "        json_output(json_data, f, path = 'output/' + year)\n",
    "        pbar.set_postfix_str(fname + \" has been processed.\")\n",
    "        \n",
    "    else: # else... no need to process a file that has been processed\n",
    "        pbar.set_postfix_str(fname.replace('.xml', '.json') + \" already exists.\")\n",
    "\n",
    "print(\"All the files have been processed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
